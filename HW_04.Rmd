---
title: "STAT 545 HW 04"
author: "Elijah Willie"
date: "October 8, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction

# Data Reshaping Prompts (and relationship to aggregation)

## Activity - Make your own cheatsheet

I will be making a cheatsheet about tidying, splitting and applying functions to data. For this I will be using two separate datasets. First I will demonstrate tidying using the billboards top 100 dataset, and second I will demonstrate splitting and applying using a dataset from my previous university

### Load the required libraries and data
```{r}
library(tidyverse) # loads dplyr, ggplot2, tidyr, etc
library(dplyr)
```

### load in the required datasets
```{r}
#load in the billboard dataset
bill_board.data <- read.csv("billboard.csv",stringsAsFactors = FALSE)

#load in the sfu statistics dataset
load("scilong.RData")
```


### Get a feel for the datasets
```{r}
knitr::kable(head(bill_board.data))
knitr::kable(head(scilong))
```

#### Structure of the billboard dataset(taken from online)

- Columns `year` through `date.peaked` describe the song,
then `x1st.week` through `x76th.week` are the 
chart positions for the first through 76th weeks. 
    - If a song is on the chart for less than 76 weeks, its position is `NA` for any missing weeks.
- Weeks are not variables, they are the time data for the 
time series.



#### Looking at the billboard dataset, it seems pretty messy. So lets tidy it up a bit.

- Main idea is gather the rankings in the different weeks into a `rank` variable. 
- Before gathering, may need to select/rename some of the variables.
- After gathering, will create some new variables and  sort the data frame.

####  I will select and rename some of the variables

- I don't think I will need `time` or `genre`, as it does not seem relevant for my cause.
    - Use the `select()` function from `dplyr`. You can us `-` to de-select a column
- Rename `artist.inverted` as it does not seem too appropriate.
    - `rename()` from `dplyr` takes arguments of the form
    `newname = oldname`

```{r}
bill_board.data <- 
  bill_board.data %>% select(-time,-genre) %>% 
  rename(artist = artist.inverted) 

knitr::kable(head(bill_board.data))
```

Now that looks somewhat better.

#### use the gather function tidying up the weeks column in the dataset

```{r}
# gather (data, key, value, ... ) where ... are the columns to collapse
bill_board.datalong <- gather(bill_board.data,week,rank,x1st.week:x76th.week,na.rm=TRUE)
knitr::kable(head(bill_board.datalong))
```

Now that is looking much better.

#### Finally I will be doing some final touch ups that will incorporate the use of fuctions such as `parse_number()`, `mutate()`, `as.date()`, and `arrange()`.

- Extract week numbers from `week` variable using the `parse_number()` function.
- Coerce `date.entered` to a `Date` object using the `as.date()` function.
- Calculate the date of each ranking based on the date it entered the charts and the week.
- Remove the date each ranking was entered since it is not relevant anymore.
- Sort the resulting dataset on artist, track and week using the `arrange()` function.

```{r}
bill_board.data <- 
  bill_board.datalong %>% mutate(week = parse_number(week), #parse the week column
              date = as.Date(date.entered) + 7*(week-1)) %>% #compute the date object
  select(-date.entered) %>% # don't need date.entered anymore
  arrange(artist,track,week) #sort the resulting dataset
knitr::kable(head(bill_board.data))
```

Now that just looks perfect. We started with a super messy dataset, and now we have tidied it up to something that looks a lot cleaner and less cluttered while retaining all of the relevant informations. 

# Join Prompts (join, merge, look up)

- In this section I will be exploring the various ways to merge two set of data. I will be comparing functions provided by base R and others provided in the tidyverse library. Particularly, I will be exploring inner joins, and outer joins. I will be using a synthetic dataset. I will also be analyzing the match function provided in base R.

## Explore the base R function merge(), which also does joins. Compare and contrast with dplyr joins.

### Load in, and get a feel for the dataset
```{r}
#define two dataframes I will be using for my analyses
#define the station dataframe
STATION <- data.frame(ID=c(13,44,66),
    City = c("Phoenix","Denver","Caribou"),
    State = c("AZ","CO","ME"),
    Lat_N = c(33,40,47),
    Long_W = c(112,105,68))
#define the stats dataframe
STATS <- data.frame(row = 1:6,
    ID = c(13,13,44,44,66,66),
    Month = c(1,7,1,7,1,7),
    Temp_F = c(57.4,91.7,27.3,74.8,6.7,65.8),
    Rain_I = c(0.31,5.15,0.18,2.11,2.1,4.52))

#create a singe dataframes for downstream illustrations
miami <- data.frame(ID=77,City="Miami",State="FL",Lat_N=26,Long_W=80)
temp <- data.frame(row=7, ID=89, Month=4, Temp_F=100, Rain_I=3.5)


#view the airlines dataframe
knitr::kable(head(STATION))

#view the flights dataframe
knitr::kable(head(STATS))
```

- Add miami to the station dataframe
```{r}
STATION <- rbind(STATION,miami)
```

- Add temp to STATs dataframe
```{r}
STATS <- rbind(STATS,temp)
```


### Inner joins

- An inner join is quite simple in that it matches pairs of observations whenever their keys are equal. Refer to figure below
![](inner_join.png)

- I will be demonstrating inner joins using dplyr and base R

```{r}
#join the tables using dplyr functions
my.data <- inner_join(STATION, STATS, by = "ID")

knitr::kable(my.data)
```

- Now do the same as above, but instead use base r functions

```{r}
my.data.new <- merge(STATION, STATS, by = "ID")
knitr::kable(head(my.data.new))
```


- Comparing the tables returned from using dplyr vs base R, we see that they are the same. The `merge()` of base R is equilvalent to the `inner_join()` function of dplyr.
- Also note that inner join is only done on fields that match in both datasets, so we do not see miami in the resulting table.



### Outer joins
- Outer joins is comprised of a set of three types of joins. Particularly left_join, right_join and full_join.
- Left join keeps all the observations in x
- Right join keeps all the observations in y
- Full join all the observations in both x and y
- Refer to figure below

![](outer_joins.png)

- Use dplyr functions to perform an left join between the station table and the stats
table on ID.

```{r}
#use dplyr to perform left join
data.left <- left_join(STATION, STATS, by = "ID")
knitr::kable(data.left)
```


- Do the left join using base R `merge()` function

```{r}
#perform a left merge using base R
data.left.new <- merge(STATION,STATS,by="ID",all.x=TRUE)
knitr::kable(data.left.new)
```

- Again we see that both methods returns the same result.
- The only difference between the two is that dpylr has an explicit left merge function where as with base R, it is an extra parameter passed in.

- Use dplyr functions to perform an right join between the station table and the stats
table on ID.

```{r}
#use dplyr to peform a right join
data.right <- right_join(STATION,STATS,by="ID")
knitr::kable(data.right)
```

- Now do the same thing using the `merge()` in base R.

```{r}
data.right.new <- merge(STATION,STATS,by="ID",all.y=TRUE)
knitr::kable(data.right.new)
```


- Again we see that both methods returns the same result.
- The only difference between the two is that dpylr has an explicit left merge function where as with base R, it is an extra parameter passed in.



- Use dplyr functions to perform an full join between the station table and the stats
table on ID.
```{r}
data.full <- full_join(STATION,STATS,by="ID")
knitr::kable(data.full)
```

- Now do the same thing using the `merge()` in base R.

```{r}
data.full.new <- merge(STATION,STATS,by="ID", all = TRUE)
knitr::kable(data.full.new)
```

- In summary, both dplyr and base R provides functions that enables us to perform various sorts of joins on our datasets. The only difference is that, with dplyr we have eplicit functions for each type of joins and with base R, it is all packaged into a single `merge()` function. The packages may be different, but the functionalities remains the same. Also, using different types of joins enables us some flexibility with how we would like to restructure our dataset

## Explore the base R function match(), which is related to joins and merges, but is really more of a "table lookup". Compare and contrast with a true join/merge.

- The match function in base R essentially checks for the first occurence of a dataframe in another dataframe. If the condition is satisfied, it returns the index of the value, or else it returns NA.
- I will demonstrate with an example

```{r}
#match the occurence of ID STATION vs STATS
result <- match(STATION$ID, STATS$ID)

knitr::kable(result)


```

- The above results show us that STATION and STATS ID match on fields 1, 3, and 5 Respectively. We also see that there is one non matching which is returned as `NA`.
- Another thing to note is that the length of the result vector will be equal to the length of the query vector. In our case, the length of the result vector is equal to the length of the STATION dataframe.
- Finally, to compare the match function with the merge/join function. I think the match function is a subroutine of the merge/join function. It finds all the row or indices where the join condition is true and the merge/join function then combines both datframes based on these indices.
- Essentially, one could implement their own merge/join function by calling the match function on a field bewteen two dataframes and then concatinating the rows where the fields match.



